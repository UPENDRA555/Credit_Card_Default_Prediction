{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "OB4l2ZhMeS1U",
        "dJ2tPlVmpsJ0",
        "D2l_nT3WhW4b",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Credit Card Default Prediction**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Upendra Pratap Singh\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project is aimed at predicting the case of customers' default payments in Taiwan. From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable than the binary result of classification - credible or not credible clients. We can use the K-S chart to evaluate which customers will default on their credit card payments."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA DISCRIPTION"
      ],
      "metadata": {
        "id": "KPpayvPEg1UE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables\n",
        "\n",
        "\n",
        "\n",
        "*   LIMIT_BAL - Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
        "*   SEX- Gender (1 = male; 2 = female).\n",
        "\n",
        "*   EDUCATION- (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
        "*   MARRIAGE- Marital status (1 = married; 2 = single; 3 = others).\n",
        "\n",
        "*   AGE- Age (year).\n",
        "*   PAY_0- PAY_6 -History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: PAY_0 = the repayment status in September, 2005;\n",
        "  PAY_2 = the repayment status in August, 2005; . . .;\n",
        "  PAY_6 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two   months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\n",
        "\n",
        "*   BILL_AMT1- BILL_AMT6- Amount of bill statement (NT dollar). BILL_AMT6 = amount of bill statement in September, 2005;\n",
        "  BILL_PAY13 = amount of bill statement in August, 2005; . . .;\n",
        "  BILL_PAY17 = amount of bill statement in April, 2005.\n",
        "*   PAY_AMT1-PAY_AMT6- Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005.\n",
        "\n",
        "*   default payment next month- default payment (Yes = 1, No = 0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FoVS5nse8eyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/UPENDRA555/Credit_Card_Default_Prediction/tree/main\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *** Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_UC_j56dxGnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/default of credit card clients.xls', header= 1)"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "HJRT-v8xx7Lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print('The row & column count')\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicate_value=len(df[df.duplicated()])\n",
        "print('The number of duplicate value in theis data:', duplicate_value)"
      ],
      "metadata": {
        "id": "7QXMthHjifpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "def show_missing():\n",
        "    missing = df.columns[df.isnull().any()].tolist()\n",
        "    return missing\n",
        "\n",
        "# Missing data counts and percentage\n",
        "print('Missing Data Count')\n",
        "print(df[show_missing()].isnull().sum().sort_values(ascending = False))\n",
        "print('--'*50)\n",
        "print('Missing Data Percentage')\n",
        "print(round(df[show_missing()].isnull().sum().sort_values(ascending = False)/len(df)*100,2))"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "qBGCkhuwujxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No Missing value is present in the dataset"
      ],
      "metadata": {
        "id": "lQuk_wuQ6ObI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values use missingo\n",
        "!pip install missingno"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a Distplot of missing value\n",
        "import missingno as msno\n",
        "msno.matrix(df)"
      ],
      "metadata": {
        "id": "T1VK4c0buu-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a bar graph of missing value\n",
        "msno.bar(df)"
      ],
      "metadata": {
        "id": "Wjo9FU-Pu0c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *** Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe().transpose()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "data = df.copy()\n",
        "data.drop(columns= 'ID', inplace= True)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "qVQiFgjzQslU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "kL845jWywgf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see that all the 24 columns have 30000 count which indicates there is no missing value.\n",
        "we can see that the repayment status is indicated in columns PAY_0, PAY_2 ... with no PAY_1 column, so we rename PAY_0 to PAY_1 and 'default payment next month' to 'target_default' for ease of understanding."
      ],
      "metadata": {
        "id": "L4cHfeehAYgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.rename(columns={'PAY_0':'PAY_1'}, inplace=True)\n",
        "data.rename(columns={'default payment next month':'target_default'}, inplace=True)"
      ],
      "metadata": {
        "id": "KOZHvolmAP8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "S4Wl67RaAVgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove Duplicate Value"
      ],
      "metadata": {
        "id": "m5PDadl0ClrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Duplicate values in the dataset\n",
        "data = data.drop_duplicates(subset=[col for col in data.columns if col != 'target_default'])\n",
        "data.shape"
      ],
      "metadata": {
        "id": "RM0M_-IeScTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "Yzb9-t4RSQR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "next we check the datatype of each variable of dataset. We see that all the columns are int64 type whereas from previous knowledge we know that SEX, EDUCATION, MARRIAGE, PAY_1, PAY_2, PAY_3, PAY_4, PAY_5, PAY_6, default payment next month are categorical features. So we convert these features in categorical"
      ],
      "metadata": {
        "id": "a9kp_swtT70G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# change the datatype of categorical features from integer to category\n",
        "data['SEX']=data['SEX'].astype('category',copy=False)\n",
        "data['EDUCATION']=data['EDUCATION'].astype('category')\n",
        "data['MARRIAGE']=data['MARRIAGE'].astype('category')\n",
        "data['PAY_1']=data['PAY_1'].astype('category')\n",
        "data['PAY_2']=data['PAY_2'].astype('category')\n",
        "data['PAY_3']=data['PAY_3'].astype('category')\n",
        "data['PAY_4']=data['PAY_4'].astype('category')\n",
        "data['PAY_5']=data['PAY_5'].astype('category')\n",
        "data['PAY_6']=data['PAY_6'].astype('category')\n",
        "data['target_default']=data['target_default'].astype('category')"
      ],
      "metadata": {
        "id": "se0kztiJU6TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "id": "GtVFzf7Julp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Categorical Features"
      ],
      "metadata": {
        "id": "ifQgw4xJ51CM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SEX\n",
        "\n",
        "\n",
        "*   1- Male\n",
        "*   2- Female\n",
        "\n"
      ],
      "metadata": {
        "id": "-THLwlHO6DAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['SEX'].value_counts()"
      ],
      "metadata": {
        "id": "mOEU2lNxXLBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Education\n",
        "\n",
        "1 = graduate school; 2 = university; 3 = high school; 4 = others"
      ],
      "metadata": {
        "id": "K1MpgW7t6ZYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['EDUCATION'].value_counts()"
      ],
      "metadata": {
        "id": "xbghsUZK6hqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see in dataset we have values like 5,6,0 as well for which we are not having description so we can add up them in 4, which is Others."
      ],
      "metadata": {
        "id": "E_1Rvc1jj-9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"EDUCATION\"] = data[\"EDUCATION\"].replace({0:4,5:4,6:4})\n",
        "data[\"EDUCATION\"].value_counts()"
      ],
      "metadata": {
        "id": "Zdhp7_s664ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Marriage\n",
        "\n",
        "1 = married; 2 = single; 3 = others"
      ],
      "metadata": {
        "id": "FwxUj3R08JD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['MARRIAGE'].value_counts()"
      ],
      "metadata": {
        "id": "eDPvjLpf8OKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have few values for 0, which are not determined . So I am adding them in Others category."
      ],
      "metadata": {
        "id": "6v48jBcckGX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"MARRIAGE\"] = data[\"MARRIAGE\"].replace({0:3})\n",
        "data[\"MARRIAGE\"].value_counts()"
      ],
      "metadata": {
        "id": "QcljyzDB8eSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features= data[['SEX', 'EDUCATION', 'MARRIAGE']]\n",
        "categorical_features.head()"
      ],
      "metadata": {
        "id": "XWRNertl9S-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Renaming Columns***"
      ],
      "metadata": {
        "id": "iXZr0hL6kV_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#renaming columns\n",
        "data.rename(columns={'PAY_1':'PAY_SEPT','PAY_2':'PAY_AUG','PAY_3':'PAY_JUL','PAY_4':'PAY_JUN','PAY_5':'PAY_MAY','PAY_6':'PAY_APR'},inplace=True)\n",
        "data.rename(columns={'BILL_AMT1':'BILL_AMT_SEPT','BILL_AMT2':'BILL_AMT_AUG','BILL_AMT3':'BILL_AMT_JUL','BILL_AMT4':'BILL_AMT_JUN','BILL_AMT5':'BILL_AMT_MAY','BILL_AMT6':'BILL_AMT_APR'}, inplace = True)\n",
        "data.rename(columns={'PAY_AMT1':'PAY_AMT_SEPT','PAY_AMT2':'PAY_AMT_AUG','PAY_AMT3':'PAY_AMT_JUL','PAY_AMT4':'PAY_AMT_JUN','PAY_AMT5':'PAY_AMT_MAY','PAY_AMT6':'PAY_AMT_APR'},inplace=True)"
      ],
      "metadata": {
        "id": "hZm5EGh-W9t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "History payment status"
      ],
      "metadata": {
        "id": "F_9LEQ52YMIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pay_col = ['PAY_SEPT',\t'PAY_AUG',\t'PAY_JUL',\t'PAY_JUN',\t'PAY_MAY',\t'PAY_APR']"
      ],
      "metadata": {
        "id": "HhlEl93OYNqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paid Amount"
      ],
      "metadata": {
        "id": "bBGiZeI2YUYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pay_amnt_df = data[['PAY_AMT_SEPT',\t'PAY_AMT_AUG',\t'PAY_AMT_JUL',\t'PAY_AMT_JUN',\t'PAY_AMT_MAY',\t'PAY_AMT_APR']]"
      ],
      "metadata": {
        "id": "DnVZ_sUQYVZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total Bill Amount"
      ],
      "metadata": {
        "id": "QJY4UNsKZkEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bill_amnt_df = data[['BILL_AMT_SEPT', 'BILL_AMT_AUG', 'BILL_AMT_JUL', 'BILL_AMT_JUN', 'BILL_AMT_MAY', 'BILL_AMT_APR']]"
      ],
      "metadata": {
        "id": "Ey4msz68ZlTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features= data.select_dtypes(include=['int64', 'float64'])\n",
        "numerical_features.head()"
      ],
      "metadata": {
        "id": "R8-Lwy_P9Qdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***EDA(Exploratory Data Analysis)***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dependent Variable Analysis"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Dependent variable analysis of the dataset\n",
        "# Find a total count of a dependent variable churn\n",
        "data['target_default'].value_counts()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a pie chart and bar chart of dependent feature\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "data[\"target_default\"].value_counts().plot.pie( figsize= (40, 40), fontsize=10, autopct= \"%1.2f%%\")\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "data[\"target_default\"].value_counts().plot(kind= 'bar', figsize= (10, 10), fontsize=20)\n",
        "plt.xlabel('default type')\n",
        "plt.ylabel('default Count')\n",
        "plt.suptitle(\"default Percentage by Customer\", fontsize=25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OIodVecB0OPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   As we can see from above graph that both classes are not in proportion and we have imbalanced dataset.\n",
        "*   The number of default a credit card is 6622(22.11%) of total card holder and 23322(77.89%) are not default.\n",
        "\n"
      ],
      "metadata": {
        "id": "sa5cJqARk4c3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For Categorical data Univariate analysis"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find a unique value of categorical variable\n",
        "for colm in categorical_features:\n",
        "  data[colm].unique()\n",
        "  print('----------------------------------------------------------------------------------------------------------------------------------')\n",
        "  print(colm)\n",
        "  print(data[colm].unique())"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find a total count of a unique value\n",
        "for colm in categorical_features:\n",
        "  data[colm].value_counts()\n",
        "  print('---------------------------------------------------------------------------------')\n",
        "  print(data[colm].value_counts())\n"
      ],
      "metadata": {
        "id": "DrAfeykX3kOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a bar graph of a categorical feature\n",
        "for colm in categorical_features:\n",
        "  data[colm].value_counts().plot(kind= 'bar', figsize= (10, 10), fontsize=10, width= 0.3)\n",
        "  plt.xlabel(colm)\n",
        "  plt.ylabel('Count')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "z1CuhBZm4QS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are few observations for categorical features:\n",
        "\n",
        "*   Female are more card hoder then male\n",
        "*   Univerity pass out are more card holder then other\n",
        "\n",
        "*   Single are more card holder then married and other\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BdlxYicoljR-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For Categorical data bivariate analysis with target feature churn"
      ],
      "metadata": {
        "id": "_p8jRXzv4brn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for colm in categorical_features:\n",
        "  pd.crosstab(colm, data['target_default'] )\n",
        "  print('------------------------------------------------------------')\n",
        "  print(pd.crosstab(colm, data['target_default'] ))"
      ],
      "metadata": {
        "id": "hc5BZ9Op50YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a bar graph between a categorical feature and categorical feature\n",
        "for colm in categorical_features:\n",
        "  fig, ax = plt.subplots(figsize=(15,10))\n",
        "\n",
        "  ax = sns.countplot(x=data[colm], hue='target_default', data=data, width= 0.5)\n",
        "  ax.set_ylabel('COUNTS', rotation=0, labelpad=100,size=10)\n",
        "  ax.set_xlabel(colm)\n",
        "  ax.yaxis.set_label_coords(0.03, 0.75)\n",
        "  ax.tick_params(labelsize=10)"
      ],
      "metadata": {
        "id": "E2gjUEnF6PRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "observations for categorical features:\n",
        "\n",
        "\n",
        "*   There are more females credit card holder,so no. of defaulter have high proportion of females.\n",
        "*   No. of defaulters have a higher proportion of educated people (graduate school and university)\n",
        "\n",
        "*   No. of defaulters have a higher proportion of Singles.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l6Ag1D-cnw5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a bar graph between a categorical feature and target feature\n",
        "for colm in pay_col:\n",
        "  fig, ax = plt.subplots(figsize=(15,10))\n",
        "\n",
        "  ax = sns.countplot(x=data[colm], hue='target_default', data=data, width= 0.5)\n",
        "  ax.set_ylabel('COUNTS', rotation=0, labelpad=100,size=10)\n",
        "  ax.set_xlabel(colm)\n",
        "  ax.yaxis.set_label_coords(0.03, 0.75)\n",
        "  ax.tick_params(labelsize=10)"
      ],
      "metadata": {
        "id": "-Rp3pbjAaIVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For numerical data  analysis"
      ],
      "metadata": {
        "id": "_1ibwIWA6y56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for colm in numerical_features:\n",
        "  ax = data.groupby('target_default')[colm].mean()\n",
        "  print('--------------------------------------------------------------------')\n",
        "  print(pd.DataFrame(ax))"
      ],
      "metadata": {
        "id": "1h8HIuFCwcgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a distplot of a 'LIMIT_BAL' features\n",
        "sns.displot(x=data['LIMIT_BAL'], kde=True)"
      ],
      "metadata": {
        "id": "4k6zNRRJ62xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a distplot of a 'LIMIT_BAL' features\n",
        "data.boxplot(column='LIMIT_BAL', by='target_default')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pieFK-mPpfdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a barplot of a 'LIMIT_BAL' features\n",
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "\n",
        "ax = sns.barplot(y=data['LIMIT_BAL'], x='target_default', data=data, width= 0.5)\n",
        "ax.set_ylabel('COUNTS', rotation=0, labelpad=100,size=10)\n",
        "ax.set_xlabel('LIMIT_BAL')\n",
        "ax.yaxis.set_label_coords(0.03, 0.75)\n",
        "ax.tick_params(labelsize=10)"
      ],
      "metadata": {
        "id": "7BqNaOPbqAE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count a number of people in different age\n",
        "data['AGE'].value_counts()"
      ],
      "metadata": {
        "id": "GGwr5U_HtVY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a barplot of different age\n",
        "plt.figure(figsize=(8,6))\n",
        "data['AGE'].value_counts().plot(kind= 'bar', figsize= (10, 10), fontsize=10, width= 0.6)\n",
        "plt.xlabel('AGE')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vpl0yLDEtCAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab('AGE', data['target_default'] )"
      ],
      "metadata": {
        "id": "MdflHU-Eu0hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a countplot of different age and default value\n",
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "\n",
        "ax = sns.countplot(x=data['AGE'], hue='target_default', data=data, width= 0.5)\n",
        "ax.set_ylabel('COUNTS', rotation=0, labelpad=100,size=10)\n",
        "ax.set_xlabel('AGE')\n",
        "ax.yaxis.set_label_coords(0.03, 0.75)\n",
        "ax.tick_params(labelsize=10)"
      ],
      "metadata": {
        "id": "KYtawJUfsOkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a distplot of a 'LIMIT_BAL' features\n",
        "data.boxplot(column='AGE', by='target_default')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KrbtGFCiwBUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Correlation Heatmap of the dataset"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize=(25,20))\n",
        "sns.heatmap(data.corr(),annot=True,cmap=\"coolwarm\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pair Plot of dataset"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot  pair plot of Total Paid Amount\n",
        "sns.pairplot(data = pay_amnt_df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KQjw4tuZ0nui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot  pair plot of Total Bill Amount\n",
        "sns.pairplot(data = bill_amnt_df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1xpLVKoFwzGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resampling The Datasets"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resampling the dataset\n",
        "data['target_default'].value_counts()\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasat is highely Inbalence so resampling is required, use a SMOTE(Synthetic Minority Oversampling Technique) technoque for resampling\n",
        "\n"
      ],
      "metadata": {
        "id": "d4Lzj8pW3ho2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "smote = SMOTE()\n",
        "\n",
        "# fit predictor and target variable\n",
        "x_smote, y_smote = smote.fit_resample(data.iloc[:,0:-1], data['target_default'])\n",
        "\n",
        "print('shape of Dataset Before Resampling', len(data))\n",
        "print('shape of Dataset After Resampling', len(y_smote))"
      ],
      "metadata": {
        "id": "FKz9YXhM3gaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of X {}'.format(x_smote.shape))\n",
        "print('Shape of y {}'.format(y_smote.shape))"
      ],
      "metadata": {
        "id": "8OlXFJp9UG4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = list(data.columns)"
      ],
      "metadata": {
        "id": "jsz6jWLhWX8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extrat the last column in the datsets\n",
        "columns.pop()"
      ],
      "metadata": {
        "id": "ZfCWItMfWe-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balance_data = pd.DataFrame(x_smote, columns=columns)"
      ],
      "metadata": {
        "id": "kYJGRf6pWo_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balance_data = pd.concat([x_smote,y_smote],axis=1)\n",
        "print('Normal distributed dataset shape {}'.format(balance_data.shape))"
      ],
      "metadata": {
        "id": "bs3C0Bg_Ine5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balance_data['target_default'] = y_smote"
      ],
      "metadata": {
        "id": "BMARBie5WxY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a barplot of balence datasets\n",
        "balance_data[\"target_default\"].value_counts().plot(kind= 'bar', figsize= (10, 10), fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U3Njm8VWcqDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show a datasets of default card holder\n",
        "balance_data[balance_data['target_default']==1]"
      ],
      "metadata": {
        "id": "vu7J3WyfYcNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One Hot Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balance_data.replace({'SEX': {1 : 'MALE', 2 : 'FEMALE'}, 'EDUCATION' : {1 : 'graduate school', 2 : 'university', 3 : 'high school', 4 : 'others'}, 'MARRIAGE' : {1 : 'married', 2 : 'single', 3 : 'others'}}, inplace = True)"
      ],
      "metadata": {
        "id": "Dw5aM-r-7l9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balance_data.head()\n"
      ],
      "metadata": {
        "id": "fHBQJ5H8eXeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "balance_data= pd.get_dummies(balance_data, columns= ['EDUCATION', 'MARRIAGE'])\n",
        "balance_data.head()\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balance_data.drop(['EDUCATION_others','MARRIAGE_others'],axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "St2bU2qNfdiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balance_data = pd.get_dummies(balance_data, columns = ['PAY_SEPT',\t'PAY_AUG',\t'PAY_JUL',\t'PAY_JUN',\t'PAY_MAY',\t'PAY_APR'], drop_first = True )"
      ],
      "metadata": {
        "id": "xeXBDkFVfrU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balance_data.shape"
      ],
      "metadata": {
        "id": "LXjLtOjLVREG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LABEL ENCODING FOR SEX\n",
        "encoders_nums = {\n",
        "                 \"SEX\":{\"FEMALE\": 0, \"MALE\": 1}\n",
        "}\n",
        "balance_data = balance_data.replace(encoders_nums)"
      ],
      "metadata": {
        "id": "Nf9wwtdogqpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balance_data.head()"
      ],
      "metadata": {
        "id": "dXV6CGjKgw50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balance_data.info()"
      ],
      "metadata": {
        "id": "_pCCIg526Enl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "data_X = balance_data.drop(['target_default'], axis=1)\n",
        "data_y = balance_data['target_default']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.2, random_state=10)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a 20% of the dataset as a test data rest 80% as a train datasets"
      ],
      "metadata": {
        "id": "JulYcnQE3Jue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "data_X = scaler.fit_transform(data_X)"
      ],
      "metadata": {
        "id": "vTNsoqoOz8R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LogisticRegression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a Logistic Regression to fit the algorithm anf fit the model\n",
        "log = LogisticRegression()\n",
        "log.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = log.predict(X_train)\n",
        "y_test_pred = log.predict(X_test)\n",
        "\n",
        "y_train_proba = log.predict_proba(X_train)\n",
        "y_test_proba = log.predict_proba(X_test)\n",
        "\n",
        "print('Classification Report for train data:\\n', classification_report(y_train_pred, y_train, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_train = confusion_matrix(y_train_pred, y_train)\n",
        "print('Confusion matrix for train data:\\n', cm_train )\n",
        "\n",
        "print('--------------------------------------------------------------------')\n",
        "\n",
        "print('Classification Report for test data:\\n', classification_report(y_test_pred, y_test, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_test= confusion_matrix(y_test_pred, y_test)\n",
        "print('Confusion matrix for train data:\\n', cm_test )\n",
        "\n",
        "print('-----------------------------------------------------------------------')\n",
        "# Get the accuracy scores\n",
        "train_accuracy_log = accuracy_score(y_train_pred,y_train)\n",
        "test_accuracy_log = accuracy_score(y_test_pred,y_test)\n",
        "\n",
        "print('\\nAccuracy Score for train data: ', train_accuracy_log)\n",
        "print('\\nAccuracy Score for test data: ', test_accuracy_log)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print('Heat map of confusion matrix for train data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_train, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()\n",
        "\n",
        "print('------------------------------------------------------------------------------------------------------------------')\n",
        "\n",
        "print('Heat map of confusion matrix for test data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_test, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = roc_auc_score(y_train, y_train_pred)\n",
        "print(f\"ROC AUC: {score:.4f}\")\n",
        "fpr, tpr, _ = roc_curve(y_train, y_train_pred)\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9BvEWTYlXWSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a GridSearch CV for the hyperparameter tuning\n",
        "param_grid = {'penalty':['l1','l2'], 'C' :np.logspace(-4, 4, 50) }\n",
        "\n",
        "grid_log_clf = GridSearchCV(LogisticRegression(), param_grid= param_grid, scoring = 'accuracy', n_jobs = -1, verbose = 3, cv = 5)\n",
        "grid_log_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_log_clf.best_params_"
      ],
      "metadata": {
        "id": "nFzNxuGJGQgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_log_clf.best_score_"
      ],
      "metadata": {
        "id": "TQJigjgxF8U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optaind_clf = grid_log_clf.best_estimator_\n",
        "print(optaind_clf)"
      ],
      "metadata": {
        "id": "mamy6glfJjIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = optaind_clf.predict(X_train)\n",
        "y_test_pred = optaind_clf.predict(X_test)\n",
        "\n",
        "y_train_proba = optaind_clf.predict_proba(X_train)\n",
        "y_test_proba = optaind_clf.predict_proba(X_test)\n",
        "\n",
        "print('Classification Report for train data:\\n', classification_report(y_train_pred, y_train, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_train = confusion_matrix(y_train_pred, y_train)\n",
        "print('Confusion matrix for train data:\\n', cm_train )\n",
        "\n",
        "print('--------------------------------------------------------------------')\n",
        "\n",
        "print('Classification Report for test data:\\n', classification_report(y_test_pred, y_test, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_test= confusion_matrix(y_test_pred, y_test)\n",
        "print('Confusion matrix for train data:\\n', cm_test )\n",
        "\n",
        "print('-----------------------------------------------------------------------')\n",
        "# Get the accuracy scores\n",
        "train_accuracy_log_grid = accuracy_score(y_train_pred,y_train)\n",
        "test_accuracy_log_grid = accuracy_score(y_test_pred,y_test)\n",
        "\n",
        "print('\\nAccuracy Score for train data: ', train_accuracy_log_grid)\n",
        "print('\\nAccuracy Score for test data: ', test_accuracy_log_grid)"
      ],
      "metadata": {
        "id": "n2ODBTNIKGEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print('Heat map of confusion matrix for train data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_train, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()\n",
        "\n",
        "print('------------------------------------------------------------------------------------------------------------------')\n",
        "\n",
        "print('Heat map of confusion matrix for test data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_test, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = roc_auc_score(y_train, y_train_pred)\n",
        "print(f\"ROC AUC: {score:.4f}\")\n",
        "fpr, tpr, _ = roc_curve(y_train, y_train_pred)\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7Ju5J7YVVVYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a Decision Tree to fit the algorithm anf fit the model\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = tree.predict(X_train)\n",
        "y_test_pred = tree.predict(X_test)\n",
        "\n",
        "y_train_proba = tree.predict_proba(X_train)\n",
        "y_test_proba = tree.predict_proba(X_test)\n",
        "\n",
        "print('Classification Report for train data:\\n', classification_report(y_train_pred, y_train, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_train = confusion_matrix(y_train_pred, y_train)\n",
        "print('Confusion matrix for train data:\\n', cm_train )\n",
        "\n",
        "print('--------------------------------------------------------------------')\n",
        "\n",
        "print('Classification Report for test data:\\n', classification_report(y_test_pred, y_test, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_test= confusion_matrix(y_test_pred, y_test)\n",
        "print('Confusion matrix for train data:\\n', cm_test )\n",
        "\n",
        "print('-----------------------------------------------------------------------')\n",
        "# Get the accuracy scores\n",
        "train_accuracy_tree = accuracy_score(y_train_pred,y_train)\n",
        "test_accuracy_tree = accuracy_score(y_test_pred,y_test)\n",
        "\n",
        "print('\\nAccuracy Score for train data: ', train_accuracy_tree)\n",
        "print('\\nAccuracy Score for test data: ', test_accuracy_tree)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print('Heat map of confusion matrix for train data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_train, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()\n",
        "\n",
        "print('------------------------------------------------------------------------------------------------------------------')\n",
        "\n",
        "print('Heat map of confusion matrix for test data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_test, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7oMYoGWDGMww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = roc_auc_score(y_train, y_train_pred)\n",
        "print(f\"ROC AUC: {score:.4f}\")\n",
        "fpr, tpr, _ = roc_curve(y_train, y_train_pred)\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pq4wtj3DGZfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning fo Dicision Tree"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a GridSearch CV for the hyperparameter tuning\n",
        "param_grid = {'max_features': ['auto', 'sqrt', 'log2'],\n",
        "              'ccp_alpha': [0.1, .01, .001],\n",
        "              'max_depth' : [5, 6, 7, 8, 9],\n",
        "              'criterion' :['gini', 'entropy'],\n",
        "              'min_samples_split':[0.1,0.2,0.4]\n",
        "             }\n",
        "\n",
        "grid_tree_clf = GridSearchCV(DecisionTreeClassifier(), param_grid=param_grid, scoring = 'accuracy', n_jobs = -1, verbose = 3, cv = 5)\n",
        "grid_tree_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "_grFVGgVHMZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_tree_clf.best_params_"
      ],
      "metadata": {
        "id": "cJobC9e1Mhwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_tree_clf.best_score_"
      ],
      "metadata": {
        "id": "L9Hyow_vM4fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optaind_clf = grid_tree_clf.best_estimator_\n",
        "print(optaind_clf)"
      ],
      "metadata": {
        "id": "5Vjczd4ZM-kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = optaind_clf.predict(X_train)\n",
        "y_test_pred = optaind_clf.predict(X_test)\n",
        "\n",
        "y_train_proba = optaind_clf.predict_proba(X_train)\n",
        "y_test_proba = optaind_clf.predict_proba(X_test)\n",
        "\n",
        "print('Classification Report for train data:\\n', classification_report(y_train_pred, y_train, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_train = confusion_matrix(y_train_pred, y_train)\n",
        "print('Confusion matrix for train data:\\n', cm_train )\n",
        "\n",
        "print('--------------------------------------------------------------------')\n",
        "\n",
        "print('Classification Report for test data:\\n', classification_report(y_test_pred, y_test, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_test= confusion_matrix(y_test_pred, y_test)\n",
        "print('Confusion matrix for train data:\\n', cm_test )\n",
        "\n",
        "print('-----------------------------------------------------------------------')\n",
        "# Get the accuracy scores\n",
        "train_accuracy_tree_grid = accuracy_score(y_train_pred,y_train)\n",
        "test_accuracy_tree_grid = accuracy_score(y_test_pred,y_test)\n",
        "\n",
        "print('\\nAccuracy Score for train data: ', train_accuracy_tree_grid)\n",
        "print('\\nAccuracy Score for test data: ', test_accuracy_tree_grid)"
      ],
      "metadata": {
        "id": "iZYZlKSoNY4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print('Heat map of confusion matrix for train data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_train, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()\n",
        "\n",
        "print('------------------------------------------------------------------------------------------------------------------')\n",
        "\n",
        "print('Heat map of confusion matrix for test data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_test, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lgDrdMULNi81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = roc_auc_score(y_train, y_train_pred)\n",
        "print(f\"ROC AUC: {score:.4f}\")\n",
        "fpr, tpr, _ = roc_curve(y_train, y_train_pred)\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nooH1xnJNuF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RandomForest"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a Random Forest to fit the algorithm anf fit the model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_clf = RandomForestClassifier()\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = rf_clf.predict(X_train)\n",
        "y_test_pred = rf_clf.predict(X_test)\n",
        "\n",
        "y_train_proba = rf_clf.predict_proba(X_train)\n",
        "y_test_proba = rf_clf.predict_proba(X_test)\n",
        "\n",
        "print('Classification Report for train data:\\n', classification_report(y_train_pred, y_train, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_train = confusion_matrix(y_train_pred, y_train)\n",
        "print('Confusion matrix for train data:\\n', cm_train )\n",
        "\n",
        "print('--------------------------------------------------------------------')\n",
        "\n",
        "print('Classification Report for test data:\\n', classification_report(y_test_pred, y_test, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_test= confusion_matrix(y_test_pred, y_test)\n",
        "print('Confusion matrix for train data:\\n', cm_test )\n",
        "\n",
        "print('-----------------------------------------------------------------------')\n",
        "train_accuracy_rf_clf = accuracy_score(y_train_pred,y_train)\n",
        "test_accuracy_rf_clf = accuracy_score(y_test_pred,y_test)\n",
        "\n",
        "print('\\nAccuracy Score for train data: ', train_accuracy_rf_clf)\n",
        "print('\\nAccuracy Score for test data: ', test_accuracy_rf_clf)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print('Heat map of confusion matrix for train data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_train, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()\n",
        "\n",
        "print('------------------------------------------------------------------------------------------------------------------')\n",
        "\n",
        "print('Heat map of confusion matrix for test data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_test, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = roc_auc_score(y_train, y_train_pred)\n",
        "print(f\"ROC AUC: {score:.4f}\")\n",
        "fpr, tpr, _ = roc_curve(y_train, y_train_pred)\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZFzHB5myPgVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a GridSearch CV for the hyperparameter tuning\n",
        "param_grid = {'n_estimators': [100,150,200], 'max_depth': [10,20,30]}\n",
        "\n",
        "grid_rf_clf = GridSearchCV(estimator= rf_clf , param_grid=param_grid, scoring = 'accuracy', n_jobs = -1, verbose = 3, cv = 5)\n",
        "grid_rf_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_rf_clf.best_params_"
      ],
      "metadata": {
        "id": "EXe5iQrCRvOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_rf_clf.best_score_"
      ],
      "metadata": {
        "id": "RgtDgY4MR4ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optaind_clf = grid_rf_clf.best_estimator_\n",
        "print(optaind_clf)"
      ],
      "metadata": {
        "id": "78dHLvAIR8vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = optaind_clf.predict(X_train)\n",
        "y_test_pred = optaind_clf.predict(X_test)\n",
        "\n",
        "y_train_proba = optaind_clf.predict_proba(X_train)\n",
        "y_test_proba = optaind_clf.predict_proba(X_test)\n",
        "\n",
        "print('Classification Report for train data:\\n', classification_report(y_train_pred, y_train, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_train = confusion_matrix(y_train_pred, y_train)\n",
        "print('Confusion matrix for train data:\\n', cm_train )\n",
        "\n",
        "print('--------------------------------------------------------------------')\n",
        "\n",
        "print('Classification Report for test data:\\n', classification_report(y_test_pred, y_test, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_test= confusion_matrix(y_test_pred, y_test)\n",
        "print('Confusion matrix for train data:\\n', cm_test )\n",
        "\n",
        "print('-----------------------------------------------------------------------')\n",
        "train_accuracy_rf_clf_grid = accuracy_score(y_train_pred,y_train)\n",
        "test_accuracy_rf_clf_grid = accuracy_score(y_test_pred,y_test)\n",
        "\n",
        "print('\\nAccuracy Score for train data: ', train_accuracy_rf_clf_grid)\n",
        "print('\\nAccuracy Score for test data: ', test_accuracy_rf_clf_grid)"
      ],
      "metadata": {
        "id": "2wUwhkeUSUHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print('Heat map of confusion matrix for train data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_train, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()\n",
        "\n",
        "print('------------------------------------------------------------------------------------------------------------------')\n",
        "\n",
        "print('Heat map of confusion matrix for test data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_test, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3dXi2UioSZXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = roc_auc_score(y_train, y_train_pred)\n",
        "print(f\"ROC AUC: {score:.4f}\")\n",
        "fpr, tpr, _ = roc_curve(y_train, y_train_pred)\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "McCXlurzSdSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNeighborsClassifier"
      ],
      "metadata": {
        "id": "woD7w9ECft5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a KNeighborsClassifier to fit the algorithm and fit the model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = knn.predict(X_train)\n",
        "y_test_pred = knn.predict(X_test)\n",
        "\n",
        "y_train_proba = knn.predict_proba(X_train)\n",
        "y_test_proba = knn.predict_proba(X_test)\n",
        "\n",
        "print('Classification Report for train data:\\n', classification_report(y_train_pred, y_train, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_train = confusion_matrix(y_train_pred, y_train)\n",
        "print('Confusion matrix for train data:\\n', cm_train )\n",
        "\n",
        "print('--------------------------------------------------------------------')\n",
        "\n",
        "print('Classification Report for test data:\\n', classification_report(y_test_pred, y_test, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_test= confusion_matrix(y_test_pred, y_test)\n",
        "print('Confusion matrix for train data:\\n', cm_test )\n",
        "\n",
        "print('-----------------------------------------------------------------------')\n",
        "train_accuracy_knn = accuracy_score(y_train_pred,y_train)\n",
        "test_accuracy_knn = accuracy_score(y_test_pred,y_test)\n",
        "\n",
        "print('\\nAccuracy Score for train data: ', train_accuracy_knn)\n",
        "print('\\nAccuracy Score for test data: ', test_accuracy_knn)"
      ],
      "metadata": {
        "id": "RO5BxAAdftmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "M97WvdBVg8vB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print('Heat map of confusion matrix for train data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_train, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()\n",
        "\n",
        "print('------------------------------------------------------------------------------------------------------------------')\n",
        "\n",
        "print('Heat map of confusion matrix for test data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_test, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jVSfd0CEg3h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = roc_auc_score(y_train, y_train_pred)\n",
        "print(f\"ROC AUC: {score:.4f}\")\n",
        "fpr, tpr, _ = roc_curve(y_train, y_train_pred)\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8WlWox3qhG9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "D2l_nT3WhW4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a GridSearch CV for the hyperparameter tuning\n",
        "param_grid = dict(n_neighbors=list(range(1, 10)))\n",
        "\n",
        "grid_knn_clf = GridSearchCV(estimator= knn , param_grid=param_grid, scoring = 'accuracy', n_jobs = -1, verbose = 3, cv = 5)\n",
        "grid_knn_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "X_muvSOkhczz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " grid_knn_clf.best_params_"
      ],
      "metadata": {
        "id": "3SKuEm2Nhx2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_knn_clf.best_score_"
      ],
      "metadata": {
        "id": "GM9pAPH9h5bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optaind_clf = grid_knn_clf.best_estimator_\n",
        "print(optaind_clf)"
      ],
      "metadata": {
        "id": "6GR7i4aJh9rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = optaind_clf.predict(X_train)\n",
        "y_test_pred = optaind_clf.predict(X_test)\n",
        "\n",
        "y_train_proba = optaind_clf.predict_proba(X_train)\n",
        "y_test_proba = optaind_clf.predict_proba(X_test)\n",
        "\n",
        "print('Classification Report for train data:\\n', classification_report(y_train_pred, y_train, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_train = confusion_matrix(y_train_pred, y_train)\n",
        "print('Confusion matrix for train data:\\n', cm_train )\n",
        "\n",
        "print('--------------------------------------------------------------------')\n",
        "\n",
        "print('Classification Report for test data:\\n', classification_report(y_test_pred, y_test, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_test= confusion_matrix(y_test_pred, y_test)\n",
        "print('Confusion matrix for train data:\\n', cm_test )\n",
        "\n",
        "print('-----------------------------------------------------------------------')\n",
        "train_accuracy_knn_grid = accuracy_score(y_train_pred,y_train)\n",
        "test_accuracy_knn_grid = accuracy_score(y_test_pred,y_test)\n",
        "\n",
        "print('\\nAccuracy Score for train data: ', train_accuracy_knn_grid)\n",
        "print('\\nAccuracy Score for test data: ', test_accuracy_knn_grid)"
      ],
      "metadata": {
        "id": "Zqpmd_fLiJVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print('Heat map of confusion matrix for train data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_train, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()\n",
        "\n",
        "print('------------------------------------------------------------------------------------------------------------------')\n",
        "\n",
        "print('Heat map of confusion matrix for test data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_test, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "drM0Mp2ziO2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = roc_auc_score(y_train, y_train_pred)\n",
        "print(f\"ROC AUC: {score:.4f}\")\n",
        "fpr, tpr, _ = roc_curve(y_train, y_train_pred)\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tijKX7KtiU9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gaussian Naive Bayes"
      ],
      "metadata": {
        "id": "Qt9D9Ma3jUP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a Gaussian Naive Bayes to fit the algorithm and fit the model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = gnb.predict(X_train)\n",
        "y_test_pred = gnb.predict(X_test)\n",
        "\n",
        "y_train_proba = gnb.predict_proba(X_train)\n",
        "y_test_proba = gnb.predict_proba(X_test)\n",
        "\n",
        "print('Classification Report for train data:\\n', classification_report(y_train_pred, y_train, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_train = confusion_matrix(y_train_pred, y_train)\n",
        "print('Confusion matrix for train data:\\n', cm_train )\n",
        "\n",
        "print('--------------------------------------------------------------------')\n",
        "\n",
        "print('Classification Report for test data:\\n', classification_report(y_test_pred, y_test, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_test= confusion_matrix(y_test_pred, y_test)\n",
        "print('Confusion matrix for train data:\\n', cm_test )\n",
        "\n",
        "print('-----------------------------------------------------------------------')\n",
        "train_accuracy_gnb = accuracy_score(y_train_pred,y_train)\n",
        "test_accuracy_gnb = accuracy_score(y_test_pred,y_test)\n",
        "\n",
        "print('\\nAccuracy Score for train data: ', train_accuracy_gnb)\n",
        "print('\\nAccuracy Score for test data: ', test_accuracy_gnb)"
      ],
      "metadata": {
        "id": "rylDanmVjSkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "vEqdgm2tlFrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print('Heat map of confusion matrix for train data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_train, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()\n",
        "\n",
        "print('------------------------------------------------------------------------------------------------------------------')\n",
        "\n",
        "print('Heat map of confusion matrix for test data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_test, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R5KyEoRllIEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = roc_auc_score(y_train, y_train_pred)\n",
        "print(f\"ROC AUC: {score:.4f}\")\n",
        "fpr, tpr, _ = roc_curve(y_train, y_train_pred)\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qv7f02FElThw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "KldY0cbxlZP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a GridSearch CV for the hyperparameter tuning\n",
        "param_grid = {\n",
        "    'var_smoothing': np.logspace(0,-9, num=100)\n",
        "}\n",
        "\n",
        "grid_svc_clf = GridSearchCV(estimator= gnb , param_grid=param_grid, scoring = 'accuracy', n_jobs = -1, verbose = 3, cv = 5)\n",
        "grid_svc_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "mEV5Zedslb-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_svc_clf.best_params_"
      ],
      "metadata": {
        "id": "raZBAc2aliTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_svc_clf.best_score_"
      ],
      "metadata": {
        "id": "spNIZYwtlord"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optaind_clf = grid_svc_clf.best_estimator_\n",
        "print(optaind_clf)"
      ],
      "metadata": {
        "id": "soPnV7amlr8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = optaind_clf.predict(X_train)\n",
        "y_test_pred = optaind_clf.predict(X_test)\n",
        "\n",
        "y_train_proba = optaind_clf.predict_proba(X_train)\n",
        "y_test_proba = optaind_clf.predict_proba(X_test)\n",
        "\n",
        "print('Classification Report for train data:\\n', classification_report(y_train_pred, y_train, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_train = confusion_matrix(y_train_pred, y_train)\n",
        "print('Confusion matrix for train data:\\n', cm_train )\n",
        "\n",
        "print('--------------------------------------------------------------------')\n",
        "\n",
        "print('Classification Report for test data:\\n', classification_report(y_test_pred, y_test, target_names=['No defaulter', 'Defaulter']))\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_test= confusion_matrix(y_test_pred, y_test)\n",
        "print('Confusion matrix for train data:\\n', cm_test )\n",
        "\n",
        "print('-----------------------------------------------------------------------')\n",
        "train_accuracy_gnb_grid = accuracy_score(y_train_pred,y_train)\n",
        "test_accuracy_gnb_grid = accuracy_score(y_test_pred,y_test)\n",
        "\n",
        "print('\\nAccuracy Score for train data: ', train_accuracy_gnb_grid)\n",
        "print('\\nAccuracy Score for test data: ', test_accuracy_gnb_grid)"
      ],
      "metadata": {
        "id": "OUlkJxwtlvLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print('Heat map of confusion matrix for train data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_train, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()\n",
        "\n",
        "print('------------------------------------------------------------------------------------------------------------------')\n",
        "\n",
        "print('Heat map of confusion matrix for test data')\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_test, annot=True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M5LUD2Igl25h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = roc_auc_score(y_train, y_train_pred)\n",
        "print(f\"ROC AUC: {score:.4f}\")\n",
        "fpr, tpr, _ = roc_curve(y_train, y_train_pred)\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6uv4yKZml5z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Evaluating the models***"
      ],
      "metadata": {
        "id": "VVYqhI05muxM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1- Without Hyperameter Tuning"
      ],
      "metadata": {
        "id": "pFdDOrpudSyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = ['Logistic Regression', 'Decision Tree', 'RandomForest', 'KNeighborsClassifier', 'Gaussian Naive Bayes']\n",
        "train_accuracy = [train_accuracy_log, train_accuracy_tree, train_accuracy_rf_clf, train_accuracy_knn, train_accuracy_gnb]\n",
        "test_accuracy = [test_accuracy_log, test_accuracy_tree, test_accuracy_rf_clf, test_accuracy_knn, test_accuracy_gnb]\n"
      ],
      "metadata": {
        "id": "hEzeArntdGvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({'Classifier':classifiers, 'Train Accuracy': train_accuracy, 'Test Accuracy': test_accuracy})"
      ],
      "metadata": {
        "id": "ZFfo1Y8NdpZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2- After Hyperameter Tuning"
      ],
      "metadata": {
        "id": "-s4hqLj1fMpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers_grid = ['Logistic Regression Grid', 'Decision Tree Grid', 'RandomForest Grid', 'KNeighborsClassifier Grid', 'Gaussian Naive Bayes']\n",
        "train_accuracy_grid = [train_accuracy_log_grid, train_accuracy_tree_grid, train_accuracy_rf_clf_grid, train_accuracy_knn_grid, train_accuracy_gnb_grid]\n",
        "test_accuracy_grid = [test_accuracy_log_grid, test_accuracy_tree_grid, test_accuracy_rf_clf_grid, test_accuracy_knn, test_accuracy_gnb_grid]\n"
      ],
      "metadata": {
        "id": "tQtmY9_yfTz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({'Classifier':classifiers_grid, 'Train Accuracy': train_accuracy_grid, 'Test Accuracy': test_accuracy_grid})"
      ],
      "metadata": {
        "id": "1p4QhW1EfVRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   After performing the various model we the get the best accuracy form the Random forest and XGBoost classifier\n",
        "*   Gaussian Naive Bayes\t is the least accurate as compared to other models performed.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}